{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN-Lec6-Task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-m1QyAAiD8R"
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import utils\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf_cIoUJqIUt"
      },
      "source": [
        "Завантажуємо набір даних, перетворюємо розмірність та нормалізуємо дані."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiHiBdyPp4v1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d6ac32b-417b-478e-e5a5-cd39e4ee5e34"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train / 255 \n",
        "x_test = x_test / 255 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "26435584/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdlrshmPqjSi"
      },
      "source": [
        "Перетворюємо категоріальні величини в числа методом one hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKo2_E7Eq-B1"
      },
      "source": [
        "y_train = utils.to_categorical(y_train, 10)\n",
        "y_test = utils.to_categorical(y_test, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy_2Sj60rFp7"
      },
      "source": [
        "**1. Використайте різну кількість нейронів на вхідному шарі: 400, 600, 800, 1200. Аргументуйте відповідь.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HUeue3CsKfb",
        "outputId": "3027c3d3-aea7-4fe7-b319-bf7e29c572d7"
      },
      "source": [
        "neurons = [400, 600, 800, 1200]\n",
        "results = []\n",
        "\n",
        "for in_neurons in neurons:\n",
        "  model = Sequential()\n",
        "  model.add(Dense(in_neurons, input_dim=784, activation=\"relu\"))\n",
        "  model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", \n",
        "                metrics=[\"accuracy\"])\n",
        "  history = model.fit(x_train, y_train, batch_size=200, epochs=20, \n",
        "                      validation_split=0.2, verbose=1)\n",
        "  results.append((history.history['accuracy'][-1],\n",
        "                  history.history['val_accuracy'][-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 1.2526 - accuracy: 0.6329 - val_loss: 0.8691 - val_accuracy: 0.7363\n",
            "Epoch 2/20\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.7857 - accuracy: 0.7566 - val_loss: 0.7121 - val_accuracy: 0.7768\n",
            "Epoch 3/20\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.6806 - accuracy: 0.7845 - val_loss: 0.6430 - val_accuracy: 0.7929\n",
            "Epoch 4/20\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.6250 - accuracy: 0.8004 - val_loss: 0.6018 - val_accuracy: 0.8062\n",
            "Epoch 5/20\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5891 - accuracy: 0.8086 - val_loss: 0.5741 - val_accuracy: 0.8111\n",
            "Epoch 6/20\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5637 - accuracy: 0.8155 - val_loss: 0.5524 - val_accuracy: 0.8190\n",
            "Epoch 7/20\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5437 - accuracy: 0.8210 - val_loss: 0.5375 - val_accuracy: 0.8184\n",
            "Epoch 8/20\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5281 - accuracy: 0.8253 - val_loss: 0.5244 - val_accuracy: 0.8206\n",
            "Epoch 9/20\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5152 - accuracy: 0.8283 - val_loss: 0.5183 - val_accuracy: 0.8217\n",
            "Epoch 10/20\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5044 - accuracy: 0.8322 - val_loss: 0.5035 - val_accuracy: 0.8290\n",
            "Epoch 11/20\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.4951 - accuracy: 0.8342 - val_loss: 0.4965 - val_accuracy: 0.8288\n",
            "Epoch 12/20\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.4867 - accuracy: 0.8359 - val_loss: 0.4872 - val_accuracy: 0.8317\n",
            "Epoch 13/20\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.4794 - accuracy: 0.8381 - val_loss: 0.4829 - val_accuracy: 0.8334\n",
            "Epoch 14/20\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.4731 - accuracy: 0.8406 - val_loss: 0.4770 - val_accuracy: 0.8347\n",
            "Epoch 15/20\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.4670 - accuracy: 0.8421 - val_loss: 0.4707 - val_accuracy: 0.8358\n",
            "Epoch 16/20\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.4616 - accuracy: 0.8432 - val_loss: 0.4690 - val_accuracy: 0.8380\n",
            "Epoch 17/20\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.4569 - accuracy: 0.8454 - val_loss: 0.4608 - val_accuracy: 0.8403\n",
            "Epoch 18/20\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.4516 - accuracy: 0.8468 - val_loss: 0.4641 - val_accuracy: 0.8387\n",
            "Epoch 19/20\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.4478 - accuracy: 0.8480 - val_loss: 0.4568 - val_accuracy: 0.8414\n",
            "Epoch 20/20\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.4434 - accuracy: 0.8497 - val_loss: 0.4497 - val_accuracy: 0.8441\n",
            "Epoch 1/20\n",
            "240/240 [==============================] - 4s 14ms/step - loss: 1.2225 - accuracy: 0.6514 - val_loss: 0.8585 - val_accuracy: 0.7315\n",
            "Epoch 2/20\n",
            "240/240 [==============================] - 3s 13ms/step - loss: 0.7811 - accuracy: 0.7532 - val_loss: 0.7093 - val_accuracy: 0.7738\n",
            "Epoch 3/20\n",
            "240/240 [==============================] - 3s 14ms/step - loss: 0.6802 - accuracy: 0.7826 - val_loss: 0.6436 - val_accuracy: 0.7903\n",
            "Epoch 4/20\n",
            "240/240 [==============================] - 3s 14ms/step - loss: 0.6257 - accuracy: 0.7994 - val_loss: 0.6053 - val_accuracy: 0.8012\n",
            "Epoch 5/20\n",
            "240/240 [==============================] - 3s 14ms/step - loss: 0.5898 - accuracy: 0.8078 - val_loss: 0.5739 - val_accuracy: 0.8114\n",
            "Epoch 6/20\n",
            "240/240 [==============================] - 3s 13ms/step - loss: 0.5636 - accuracy: 0.8155 - val_loss: 0.5529 - val_accuracy: 0.8155\n",
            "Epoch 7/20\n",
            "240/240 [==============================] - 3s 14ms/step - loss: 0.5432 - accuracy: 0.8220 - val_loss: 0.5353 - val_accuracy: 0.8226\n",
            "Epoch 8/20\n",
            "240/240 [==============================] - 3s 13ms/step - loss: 0.5270 - accuracy: 0.8262 - val_loss: 0.5222 - val_accuracy: 0.8261\n",
            "Epoch 9/20\n",
            "240/240 [==============================] - 3s 13ms/step - loss: 0.5136 - accuracy: 0.8300 - val_loss: 0.5103 - val_accuracy: 0.8288\n",
            "Epoch 10/20\n",
            "240/240 [==============================] - 3s 14ms/step - loss: 0.5024 - accuracy: 0.8331 - val_loss: 0.5045 - val_accuracy: 0.8310\n",
            "Epoch 11/20\n",
            "240/240 [==============================] - 3s 13ms/step - loss: 0.4924 - accuracy: 0.8363 - val_loss: 0.4925 - val_accuracy: 0.8336\n",
            "Epoch 12/20\n",
            "240/240 [==============================] - 3s 13ms/step - loss: 0.4841 - accuracy: 0.8378 - val_loss: 0.4849 - val_accuracy: 0.8367\n",
            "Epoch 13/20\n",
            "240/240 [==============================] - 3s 13ms/step - loss: 0.4768 - accuracy: 0.8400 - val_loss: 0.4805 - val_accuracy: 0.8365\n",
            "Epoch 14/20\n",
            "240/240 [==============================] - 3s 13ms/step - loss: 0.4697 - accuracy: 0.8424 - val_loss: 0.4732 - val_accuracy: 0.8386\n",
            "Epoch 15/20\n",
            "240/240 [==============================] - 3s 13ms/step - loss: 0.4635 - accuracy: 0.8434 - val_loss: 0.4678 - val_accuracy: 0.8401\n",
            "Epoch 16/20\n",
            "240/240 [==============================] - 3s 13ms/step - loss: 0.4581 - accuracy: 0.8454 - val_loss: 0.4663 - val_accuracy: 0.8390\n",
            "Epoch 17/20\n",
            "240/240 [==============================] - 3s 14ms/step - loss: 0.4533 - accuracy: 0.8469 - val_loss: 0.4588 - val_accuracy: 0.8425\n",
            "Epoch 18/20\n",
            "240/240 [==============================] - 3s 13ms/step - loss: 0.4486 - accuracy: 0.8477 - val_loss: 0.4584 - val_accuracy: 0.8420\n",
            "Epoch 19/20\n",
            "240/240 [==============================] - 3s 13ms/step - loss: 0.4440 - accuracy: 0.8493 - val_loss: 0.4519 - val_accuracy: 0.8440\n",
            "Epoch 20/20\n",
            "240/240 [==============================] - 3s 13ms/step - loss: 0.4398 - accuracy: 0.8509 - val_loss: 0.4492 - val_accuracy: 0.8453\n",
            "Epoch 1/20\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 1.2014 - accuracy: 0.6546 - val_loss: 0.8443 - val_accuracy: 0.7402\n",
            "Epoch 2/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.7691 - accuracy: 0.7619 - val_loss: 0.6973 - val_accuracy: 0.7781\n",
            "Epoch 3/20\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.6693 - accuracy: 0.7884 - val_loss: 0.6331 - val_accuracy: 0.7958\n",
            "Epoch 4/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.6159 - accuracy: 0.8031 - val_loss: 0.5917 - val_accuracy: 0.8068\n",
            "Epoch 5/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5810 - accuracy: 0.8134 - val_loss: 0.5664 - val_accuracy: 0.8129\n",
            "Epoch 6/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5557 - accuracy: 0.8202 - val_loss: 0.5440 - val_accuracy: 0.8185\n",
            "Epoch 7/20\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.5365 - accuracy: 0.8241 - val_loss: 0.5287 - val_accuracy: 0.8216\n",
            "Epoch 8/20\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.5212 - accuracy: 0.8280 - val_loss: 0.5169 - val_accuracy: 0.8249\n",
            "Epoch 9/20\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.5086 - accuracy: 0.8315 - val_loss: 0.5064 - val_accuracy: 0.8303\n",
            "Epoch 10/20\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.4981 - accuracy: 0.8345 - val_loss: 0.4954 - val_accuracy: 0.8313\n",
            "Epoch 11/20\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.4888 - accuracy: 0.8372 - val_loss: 0.4888 - val_accuracy: 0.8334\n",
            "Epoch 12/20\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.4805 - accuracy: 0.8396 - val_loss: 0.4825 - val_accuracy: 0.8373\n",
            "Epoch 13/20\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.4732 - accuracy: 0.8409 - val_loss: 0.4757 - val_accuracy: 0.8378\n",
            "Epoch 14/20\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.4672 - accuracy: 0.8435 - val_loss: 0.4728 - val_accuracy: 0.8369\n",
            "Epoch 15/20\n",
            "240/240 [==============================] - 4s 18ms/step - loss: 0.4613 - accuracy: 0.8447 - val_loss: 0.4643 - val_accuracy: 0.8410\n",
            "Epoch 16/20\n",
            "240/240 [==============================] - 4s 18ms/step - loss: 0.4558 - accuracy: 0.8462 - val_loss: 0.4593 - val_accuracy: 0.8428\n",
            "Epoch 17/20\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.4506 - accuracy: 0.8480 - val_loss: 0.4568 - val_accuracy: 0.8431\n",
            "Epoch 18/20\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.4465 - accuracy: 0.8486 - val_loss: 0.4523 - val_accuracy: 0.8434\n",
            "Epoch 19/20\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.4420 - accuracy: 0.8515 - val_loss: 0.4489 - val_accuracy: 0.8453\n",
            "Epoch 20/20\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.4376 - accuracy: 0.8515 - val_loss: 0.4451 - val_accuracy: 0.8465\n",
            "Epoch 1/20\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 1.1672 - accuracy: 0.6656 - val_loss: 0.8272 - val_accuracy: 0.7463\n",
            "Epoch 2/20\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.7557 - accuracy: 0.7650 - val_loss: 0.6895 - val_accuracy: 0.7832\n",
            "Epoch 3/20\n",
            "240/240 [==============================] - 6s 23ms/step - loss: 0.6592 - accuracy: 0.7934 - val_loss: 0.6242 - val_accuracy: 0.8013\n",
            "Epoch 4/20\n",
            "240/240 [==============================] - 6s 23ms/step - loss: 0.6071 - accuracy: 0.8081 - val_loss: 0.5850 - val_accuracy: 0.8127\n",
            "Epoch 5/20\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.5722 - accuracy: 0.8164 - val_loss: 0.5568 - val_accuracy: 0.8182\n",
            "Epoch 6/20\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.5478 - accuracy: 0.8226 - val_loss: 0.5366 - val_accuracy: 0.8217\n",
            "Epoch 7/20\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.5286 - accuracy: 0.8283 - val_loss: 0.5213 - val_accuracy: 0.8282\n",
            "Epoch 8/20\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.5136 - accuracy: 0.8306 - val_loss: 0.5081 - val_accuracy: 0.8296\n",
            "Epoch 9/20\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.5009 - accuracy: 0.8352 - val_loss: 0.4982 - val_accuracy: 0.8326\n",
            "Epoch 10/20\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.4903 - accuracy: 0.8375 - val_loss: 0.4901 - val_accuracy: 0.8361\n",
            "Epoch 11/20\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.4812 - accuracy: 0.8396 - val_loss: 0.4820 - val_accuracy: 0.8372\n",
            "Epoch 12/20\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.4731 - accuracy: 0.8421 - val_loss: 0.4759 - val_accuracy: 0.8388\n",
            "Epoch 13/20\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.4663 - accuracy: 0.8447 - val_loss: 0.4700 - val_accuracy: 0.8403\n",
            "Epoch 14/20\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.4599 - accuracy: 0.8457 - val_loss: 0.4679 - val_accuracy: 0.8396\n",
            "Epoch 15/20\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.4542 - accuracy: 0.8473 - val_loss: 0.4607 - val_accuracy: 0.8435\n",
            "Epoch 16/20\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.4492 - accuracy: 0.8482 - val_loss: 0.4537 - val_accuracy: 0.8447\n",
            "Epoch 17/20\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.4439 - accuracy: 0.8510 - val_loss: 0.4513 - val_accuracy: 0.8450\n",
            "Epoch 18/20\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.4399 - accuracy: 0.8511 - val_loss: 0.4462 - val_accuracy: 0.8477\n",
            "Epoch 19/20\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.4354 - accuracy: 0.8525 - val_loss: 0.4430 - val_accuracy: 0.8486\n",
            "Epoch 20/20\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.4315 - accuracy: 0.8537 - val_loss: 0.4414 - val_accuracy: 0.8482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZebGB0Wvu91",
        "outputId": "b52bee3d-9151-4e86-cd5c-ef4800b5ffe7"
      },
      "source": [
        "for i in range(len(neurons)):\n",
        "  print(str(neurons[i]) + ' input neurons')\n",
        "  print('accuracy: ', results[i][0])\n",
        "  print('val_accuracy: ' + str(results[i][1]) + '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400 input neurons\n",
            "accuracy:  0.8496875166893005\n",
            "val_accuracy: 0.844083309173584\n",
            "\n",
            "600 input neurons\n",
            "accuracy:  0.8508750200271606\n",
            "val_accuracy: 0.8452500104904175\n",
            "\n",
            "800 input neurons\n",
            "accuracy:  0.8514999747276306\n",
            "val_accuracy: 0.8464999794960022\n",
            "\n",
            "1200 input neurons\n",
            "accuracy:  0.8537499904632568\n",
            "val_accuracy: 0.8481666445732117\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNf8xKm0m1Ua"
      },
      "source": [
        "Найбільшу точність тестування (і навчання) отримали для вхідного шару з 1200 нейронів. Чим більше нейронів у вхідному шарі, тим більша якість навчання (більший простір гіпотез), але тим відповідно більша загроза перенавчання."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPW5psbJw60I"
      },
      "source": [
        "**2. Додайте в нейронну мережу прихований шар з різною кількістю нейронів: 200, 300, 400, 600, 800. Аргументуйте відповідь.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TovdpZRxxCSh",
        "outputId": "81455582-108e-4f0f-f85c-cdbf3b4a8da1"
      },
      "source": [
        "neurons = [200, 300, 400, 600, 800]\n",
        "results = []\n",
        "\n",
        "for hidden_neurons in neurons:\n",
        "  model = Sequential()\n",
        "  model.add(Dense(800, input_dim=784, activation=\"relu\"))\n",
        "  model.add(Dense(hidden_neurons, activation=\"relu\"))\n",
        "  model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", \n",
        "                metrics=[\"accuracy\"])\n",
        "  history = model.fit(x_train, y_train, batch_size=200, epochs=20, \n",
        "                      validation_split=0.2, verbose=1)\n",
        "  results.append((history.history['accuracy'][-1],\n",
        "                  history.history['val_accuracy'][-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "240/240 [==============================] - 5s 21ms/step - loss: 1.2135 - accuracy: 0.6459 - val_loss: 0.8048 - val_accuracy: 0.7526\n",
            "Epoch 2/20\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.7189 - accuracy: 0.7709 - val_loss: 0.6476 - val_accuracy: 0.7901\n",
            "Epoch 3/20\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.6151 - accuracy: 0.8019 - val_loss: 0.5859 - val_accuracy: 0.8051\n",
            "Epoch 4/20\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.5619 - accuracy: 0.8167 - val_loss: 0.5456 - val_accuracy: 0.8193\n",
            "Epoch 5/20\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.5290 - accuracy: 0.8246 - val_loss: 0.5176 - val_accuracy: 0.8247\n",
            "Epoch 6/20\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.5049 - accuracy: 0.8304 - val_loss: 0.5050 - val_accuracy: 0.8257\n",
            "Epoch 7/20\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.4875 - accuracy: 0.8339 - val_loss: 0.4905 - val_accuracy: 0.8273\n",
            "Epoch 8/20\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.4748 - accuracy: 0.8380 - val_loss: 0.4788 - val_accuracy: 0.8353\n",
            "Epoch 9/20\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.4619 - accuracy: 0.8424 - val_loss: 0.4646 - val_accuracy: 0.8382\n",
            "Epoch 10/20\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.4529 - accuracy: 0.8443 - val_loss: 0.4549 - val_accuracy: 0.8420\n",
            "Epoch 11/20\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.4445 - accuracy: 0.8469 - val_loss: 0.4728 - val_accuracy: 0.8363\n",
            "Epoch 12/20\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.4370 - accuracy: 0.8494 - val_loss: 0.4450 - val_accuracy: 0.8442\n",
            "Epoch 13/20\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.4301 - accuracy: 0.8515 - val_loss: 0.4375 - val_accuracy: 0.8477\n",
            "Epoch 14/20\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.4242 - accuracy: 0.8540 - val_loss: 0.4353 - val_accuracy: 0.8479\n",
            "Epoch 15/20\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.4186 - accuracy: 0.8559 - val_loss: 0.4283 - val_accuracy: 0.8537\n",
            "Epoch 16/20\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.4135 - accuracy: 0.8583 - val_loss: 0.4263 - val_accuracy: 0.8513\n",
            "Epoch 17/20\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.4089 - accuracy: 0.8583 - val_loss: 0.4191 - val_accuracy: 0.8562\n",
            "Epoch 18/20\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.4047 - accuracy: 0.8597 - val_loss: 0.4163 - val_accuracy: 0.8546\n",
            "Epoch 19/20\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.4004 - accuracy: 0.8612 - val_loss: 0.4178 - val_accuracy: 0.8549\n",
            "Epoch 20/20\n",
            "240/240 [==============================] - 5s 20ms/step - loss: 0.3957 - accuracy: 0.8630 - val_loss: 0.4101 - val_accuracy: 0.8568\n",
            "Epoch 1/20\n",
            "240/240 [==============================] - 6s 23ms/step - loss: 1.2074 - accuracy: 0.6493 - val_loss: 0.8061 - val_accuracy: 0.7443\n",
            "Epoch 2/20\n",
            "240/240 [==============================] - 5s 22ms/step - loss: 0.7251 - accuracy: 0.7715 - val_loss: 0.6577 - val_accuracy: 0.7878\n",
            "Epoch 3/20\n",
            "240/240 [==============================] - 5s 22ms/step - loss: 0.6204 - accuracy: 0.8046 - val_loss: 0.5847 - val_accuracy: 0.8124\n",
            "Epoch 4/20\n",
            "240/240 [==============================] - 5s 22ms/step - loss: 0.5664 - accuracy: 0.8164 - val_loss: 0.5462 - val_accuracy: 0.8214\n",
            "Epoch 5/20\n",
            "240/240 [==============================] - 5s 22ms/step - loss: 0.5313 - accuracy: 0.8257 - val_loss: 0.5203 - val_accuracy: 0.8248\n",
            "Epoch 6/20\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.5086 - accuracy: 0.8299 - val_loss: 0.5005 - val_accuracy: 0.8303\n",
            "Epoch 7/20\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.4910 - accuracy: 0.8352 - val_loss: 0.4937 - val_accuracy: 0.8317\n",
            "Epoch 8/20\n",
            "240/240 [==============================] - 5s 22ms/step - loss: 0.4766 - accuracy: 0.8385 - val_loss: 0.4755 - val_accuracy: 0.8397\n",
            "Epoch 9/20\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.4655 - accuracy: 0.8414 - val_loss: 0.4703 - val_accuracy: 0.8367\n",
            "Epoch 10/20\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.4556 - accuracy: 0.8444 - val_loss: 0.4586 - val_accuracy: 0.8420\n",
            "Epoch 11/20\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.4464 - accuracy: 0.8470 - val_loss: 0.4503 - val_accuracy: 0.8454\n",
            "Epoch 12/20\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.4396 - accuracy: 0.8508 - val_loss: 0.4571 - val_accuracy: 0.8394\n",
            "Epoch 13/20\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.4329 - accuracy: 0.8524 - val_loss: 0.4383 - val_accuracy: 0.8466\n",
            "Epoch 14/20\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.4274 - accuracy: 0.8531 - val_loss: 0.4373 - val_accuracy: 0.8497\n",
            "Epoch 15/20\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.4214 - accuracy: 0.8555 - val_loss: 0.4356 - val_accuracy: 0.8487\n",
            "Epoch 16/20\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.4167 - accuracy: 0.8571 - val_loss: 0.4267 - val_accuracy: 0.8528\n",
            "Epoch 17/20\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.4118 - accuracy: 0.8580 - val_loss: 0.4264 - val_accuracy: 0.8509\n",
            "Epoch 18/20\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.4072 - accuracy: 0.8608 - val_loss: 0.4145 - val_accuracy: 0.8569\n",
            "Epoch 19/20\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.4039 - accuracy: 0.8612 - val_loss: 0.4160 - val_accuracy: 0.8539\n",
            "Epoch 20/20\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.3997 - accuracy: 0.8628 - val_loss: 0.4172 - val_accuracy: 0.8537\n",
            "Epoch 1/20\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 1.1918 - accuracy: 0.6583 - val_loss: 0.8084 - val_accuracy: 0.7470\n",
            "Epoch 2/20\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.7273 - accuracy: 0.7672 - val_loss: 0.6563 - val_accuracy: 0.7857\n",
            "Epoch 3/20\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.6226 - accuracy: 0.7975 - val_loss: 0.5880 - val_accuracy: 0.8052\n",
            "Epoch 4/20\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.5675 - accuracy: 0.8147 - val_loss: 0.5475 - val_accuracy: 0.8152\n",
            "Epoch 5/20\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.5325 - accuracy: 0.8235 - val_loss: 0.5228 - val_accuracy: 0.8228\n",
            "Epoch 6/20\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.5095 - accuracy: 0.8302 - val_loss: 0.5024 - val_accuracy: 0.8282\n",
            "Epoch 7/20\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.4907 - accuracy: 0.8350 - val_loss: 0.4855 - val_accuracy: 0.8324\n",
            "Epoch 8/20\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.4756 - accuracy: 0.8386 - val_loss: 0.4749 - val_accuracy: 0.8378\n",
            "Epoch 9/20\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.4628 - accuracy: 0.8422 - val_loss: 0.4709 - val_accuracy: 0.8363\n",
            "Epoch 10/20\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.4531 - accuracy: 0.8451 - val_loss: 0.4608 - val_accuracy: 0.8407\n",
            "Epoch 11/20\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.4447 - accuracy: 0.8486 - val_loss: 0.4480 - val_accuracy: 0.8449\n",
            "Epoch 12/20\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.4375 - accuracy: 0.8506 - val_loss: 0.4462 - val_accuracy: 0.8454\n",
            "Epoch 13/20\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.4307 - accuracy: 0.8524 - val_loss: 0.4385 - val_accuracy: 0.8502\n",
            "Epoch 14/20\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.4240 - accuracy: 0.8543 - val_loss: 0.4323 - val_accuracy: 0.8491\n",
            "Epoch 15/20\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.4184 - accuracy: 0.8569 - val_loss: 0.4321 - val_accuracy: 0.8494\n",
            "Epoch 16/20\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.4126 - accuracy: 0.8580 - val_loss: 0.4217 - val_accuracy: 0.8523\n",
            "Epoch 17/20\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.4068 - accuracy: 0.8597 - val_loss: 0.4250 - val_accuracy: 0.8520\n",
            "Epoch 18/20\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.4039 - accuracy: 0.8608 - val_loss: 0.4139 - val_accuracy: 0.8550\n",
            "Epoch 19/20\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.3987 - accuracy: 0.8631 - val_loss: 0.4117 - val_accuracy: 0.8576\n",
            "Epoch 20/20\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.3959 - accuracy: 0.8631 - val_loss: 0.4073 - val_accuracy: 0.8582\n",
            "Epoch 1/20\n",
            "240/240 [==============================] - 8s 31ms/step - loss: 1.2244 - accuracy: 0.6492 - val_loss: 0.8065 - val_accuracy: 0.7474\n",
            "Epoch 2/20\n",
            "240/240 [==============================] - 7s 31ms/step - loss: 0.7251 - accuracy: 0.7691 - val_loss: 0.6535 - val_accuracy: 0.7897\n",
            "Epoch 3/20\n",
            "240/240 [==============================] - 7s 30ms/step - loss: 0.6207 - accuracy: 0.7991 - val_loss: 0.5843 - val_accuracy: 0.8079\n",
            "Epoch 4/20\n",
            "240/240 [==============================] - 7s 30ms/step - loss: 0.5669 - accuracy: 0.8140 - val_loss: 0.5608 - val_accuracy: 0.8083\n",
            "Epoch 5/20\n",
            "240/240 [==============================] - 7s 30ms/step - loss: 0.5333 - accuracy: 0.8228 - val_loss: 0.5196 - val_accuracy: 0.8237\n",
            "Epoch 6/20\n",
            "240/240 [==============================] - 7s 30ms/step - loss: 0.5091 - accuracy: 0.8297 - val_loss: 0.5004 - val_accuracy: 0.8292\n",
            "Epoch 7/20\n",
            "240/240 [==============================] - 7s 30ms/step - loss: 0.4913 - accuracy: 0.8350 - val_loss: 0.4909 - val_accuracy: 0.8321\n",
            "Epoch 8/20\n",
            "240/240 [==============================] - 7s 30ms/step - loss: 0.4758 - accuracy: 0.8389 - val_loss: 0.4808 - val_accuracy: 0.8319\n",
            "Epoch 9/20\n",
            "240/240 [==============================] - 7s 30ms/step - loss: 0.4650 - accuracy: 0.8422 - val_loss: 0.4650 - val_accuracy: 0.8367\n",
            "Epoch 10/20\n",
            "240/240 [==============================] - 7s 30ms/step - loss: 0.4545 - accuracy: 0.8454 - val_loss: 0.4571 - val_accuracy: 0.8410\n",
            "Epoch 11/20\n",
            "240/240 [==============================] - 7s 30ms/step - loss: 0.4465 - accuracy: 0.8485 - val_loss: 0.4547 - val_accuracy: 0.8408\n",
            "Epoch 12/20\n",
            "240/240 [==============================] - 7s 30ms/step - loss: 0.4385 - accuracy: 0.8497 - val_loss: 0.4413 - val_accuracy: 0.8473\n",
            "Epoch 13/20\n",
            "240/240 [==============================] - 7s 30ms/step - loss: 0.4318 - accuracy: 0.8517 - val_loss: 0.4343 - val_accuracy: 0.8509\n",
            "Epoch 14/20\n",
            "240/240 [==============================] - 7s 30ms/step - loss: 0.4258 - accuracy: 0.8542 - val_loss: 0.4332 - val_accuracy: 0.8479\n",
            "Epoch 15/20\n",
            "240/240 [==============================] - 7s 30ms/step - loss: 0.4206 - accuracy: 0.8555 - val_loss: 0.4305 - val_accuracy: 0.8498\n",
            "Epoch 16/20\n",
            "240/240 [==============================] - 7s 30ms/step - loss: 0.4150 - accuracy: 0.8573 - val_loss: 0.4240 - val_accuracy: 0.8516\n",
            "Epoch 17/20\n",
            "240/240 [==============================] - 7s 30ms/step - loss: 0.4101 - accuracy: 0.8586 - val_loss: 0.4218 - val_accuracy: 0.8550\n",
            "Epoch 18/20\n",
            "240/240 [==============================] - 7s 30ms/step - loss: 0.4058 - accuracy: 0.8602 - val_loss: 0.4312 - val_accuracy: 0.8470\n",
            "Epoch 19/20\n",
            "240/240 [==============================] - 7s 30ms/step - loss: 0.4020 - accuracy: 0.8616 - val_loss: 0.4141 - val_accuracy: 0.8537\n",
            "Epoch 20/20\n",
            "240/240 [==============================] - 7s 31ms/step - loss: 0.3986 - accuracy: 0.8628 - val_loss: 0.4082 - val_accuracy: 0.8570\n",
            "Epoch 1/20\n",
            "240/240 [==============================] - 23s 35ms/step - loss: 1.2170 - accuracy: 0.6424 - val_loss: 0.8165 - val_accuracy: 0.7425\n",
            "Epoch 2/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.7356 - accuracy: 0.7681 - val_loss: 0.6610 - val_accuracy: 0.7851\n",
            "Epoch 3/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.6303 - accuracy: 0.8000 - val_loss: 0.5910 - val_accuracy: 0.8059\n",
            "Epoch 4/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.5737 - accuracy: 0.8151 - val_loss: 0.5509 - val_accuracy: 0.8170\n",
            "Epoch 5/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.5375 - accuracy: 0.8235 - val_loss: 0.5209 - val_accuracy: 0.8260\n",
            "Epoch 6/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.5121 - accuracy: 0.8302 - val_loss: 0.5030 - val_accuracy: 0.8308\n",
            "Epoch 7/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.4945 - accuracy: 0.8345 - val_loss: 0.4870 - val_accuracy: 0.8328\n",
            "Epoch 8/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.4797 - accuracy: 0.8386 - val_loss: 0.4781 - val_accuracy: 0.8353\n",
            "Epoch 9/20\n",
            "240/240 [==============================] - 8s 34ms/step - loss: 0.4675 - accuracy: 0.8425 - val_loss: 0.4721 - val_accuracy: 0.8344\n",
            "Epoch 10/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.4567 - accuracy: 0.8446 - val_loss: 0.4562 - val_accuracy: 0.8420\n",
            "Epoch 11/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.4481 - accuracy: 0.8483 - val_loss: 0.4525 - val_accuracy: 0.8438\n",
            "Epoch 12/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.4412 - accuracy: 0.8494 - val_loss: 0.4411 - val_accuracy: 0.8474\n",
            "Epoch 13/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.4342 - accuracy: 0.8515 - val_loss: 0.4353 - val_accuracy: 0.8489\n",
            "Epoch 14/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.4280 - accuracy: 0.8528 - val_loss: 0.4379 - val_accuracy: 0.8458\n",
            "Epoch 15/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.4223 - accuracy: 0.8548 - val_loss: 0.4252 - val_accuracy: 0.8522\n",
            "Epoch 16/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.4182 - accuracy: 0.8553 - val_loss: 0.4208 - val_accuracy: 0.8536\n",
            "Epoch 17/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.4119 - accuracy: 0.8586 - val_loss: 0.4170 - val_accuracy: 0.8541\n",
            "Epoch 18/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.4081 - accuracy: 0.8597 - val_loss: 0.4158 - val_accuracy: 0.8540\n",
            "Epoch 19/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.4048 - accuracy: 0.8601 - val_loss: 0.4173 - val_accuracy: 0.8533\n",
            "Epoch 20/20\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.4004 - accuracy: 0.8616 - val_loss: 0.4135 - val_accuracy: 0.8558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssZgbBRj01Ok",
        "outputId": "f04d5f21-388c-4800-98a7-f94b719949b6"
      },
      "source": [
        "for i in range(len(neurons)):\n",
        "  print(str(neurons[i]) + ' hidden layer neurons')\n",
        "  print('accuracy: ', results[i][0])\n",
        "  print('val_accuracy: ' + str(results[i][1]) + '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200 hidden layer neurons\n",
            "accuracy:  0.8629791736602783\n",
            "val_accuracy: 0.8568333387374878\n",
            "\n",
            "300 hidden layer neurons\n",
            "accuracy:  0.8628125190734863\n",
            "val_accuracy: 0.8537499904632568\n",
            "\n",
            "400 hidden layer neurons\n",
            "accuracy:  0.8631458282470703\n",
            "val_accuracy: 0.8581666946411133\n",
            "\n",
            "600 hidden layer neurons\n",
            "accuracy:  0.8628125190734863\n",
            "val_accuracy: 0.8569999933242798\n",
            "\n",
            "800 hidden layer neurons\n",
            "accuracy:  0.8616041541099548\n",
            "val_accuracy: 0.8558333516120911\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smQ2iSEkohnU"
      },
      "source": [
        "Найбільшу точність тестування (і навчання) отримали для прихованого шару з 400 нейронів. Проте насправді запропоновані кількості нейронів у прихованому шарі на якість навчання не впливають (для даного датасету): при повторенні тесту результати можуть змінитися на користь інших варіантів."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjy6tnKF1Dbe"
      },
      "source": [
        "**3. Додайте кілька прихованих шарів в мережу з різною кількістю нейронів в кожному шарі. Яким чином це впливає на якість навчання нейронної мережі.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yifCq6Av1MaQ",
        "outputId": "1601b98e-9b58-48e0-c69b-e5304ce86179"
      },
      "source": [
        "sets = [(1000, 700), (1000, 700, 500), (1000, 700, 500, 200)]\n",
        "results = []\n",
        "\n",
        "for layers in sets:\n",
        "  model = Sequential()\n",
        "  model.add(Dense(800, input_dim=784, activation=\"relu\"))\n",
        "  for layer in layers:\n",
        "    model.add(Dense(layer, activation=\"relu\"))\n",
        "  model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", \n",
        "                metrics=[\"accuracy\"])\n",
        "  history = model.fit(x_train, y_train, batch_size=200, epochs=20,\n",
        "                      validation_split=0.2, verbose=1)\n",
        "  results.append((history.history['accuracy'][-1],\n",
        "                  history.history['val_accuracy'][-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "240/240 [==============================] - 15s 63ms/step - loss: 1.2557 - accuracy: 0.6526 - val_loss: 0.7998 - val_accuracy: 0.7442\n",
            "Epoch 2/20\n",
            "240/240 [==============================] - 15s 61ms/step - loss: 0.7083 - accuracy: 0.7702 - val_loss: 0.6325 - val_accuracy: 0.7896\n",
            "Epoch 3/20\n",
            "240/240 [==============================] - 15s 62ms/step - loss: 0.6005 - accuracy: 0.7992 - val_loss: 0.5787 - val_accuracy: 0.8019\n",
            "Epoch 4/20\n",
            "240/240 [==============================] - 15s 62ms/step - loss: 0.5478 - accuracy: 0.8145 - val_loss: 0.5347 - val_accuracy: 0.8145\n",
            "Epoch 5/20\n",
            "240/240 [==============================] - 15s 62ms/step - loss: 0.5142 - accuracy: 0.8236 - val_loss: 0.5012 - val_accuracy: 0.8253\n",
            "Epoch 6/20\n",
            "240/240 [==============================] - 15s 63ms/step - loss: 0.4908 - accuracy: 0.8316 - val_loss: 0.5038 - val_accuracy: 0.8236\n",
            "Epoch 7/20\n",
            "240/240 [==============================] - 15s 62ms/step - loss: 0.4746 - accuracy: 0.8339 - val_loss: 0.4715 - val_accuracy: 0.8356\n",
            "Epoch 8/20\n",
            "240/240 [==============================] - 15s 63ms/step - loss: 0.4601 - accuracy: 0.8403 - val_loss: 0.4573 - val_accuracy: 0.8424\n",
            "Epoch 9/20\n",
            "240/240 [==============================] - 15s 63ms/step - loss: 0.4503 - accuracy: 0.8436 - val_loss: 0.4609 - val_accuracy: 0.8361\n",
            "Epoch 10/20\n",
            "240/240 [==============================] - 15s 63ms/step - loss: 0.4390 - accuracy: 0.8469 - val_loss: 0.4552 - val_accuracy: 0.8388\n",
            "Epoch 11/20\n",
            "240/240 [==============================] - 15s 63ms/step - loss: 0.4309 - accuracy: 0.8500 - val_loss: 0.4513 - val_accuracy: 0.8433\n",
            "Epoch 12/20\n",
            "240/240 [==============================] - 15s 62ms/step - loss: 0.4218 - accuracy: 0.8548 - val_loss: 0.4296 - val_accuracy: 0.8526\n",
            "Epoch 13/20\n",
            "240/240 [==============================] - 15s 63ms/step - loss: 0.4144 - accuracy: 0.8565 - val_loss: 0.4193 - val_accuracy: 0.8540\n",
            "Epoch 14/20\n",
            "240/240 [==============================] - 15s 63ms/step - loss: 0.4094 - accuracy: 0.8575 - val_loss: 0.4201 - val_accuracy: 0.8545\n",
            "Epoch 15/20\n",
            "240/240 [==============================] - 15s 62ms/step - loss: 0.4055 - accuracy: 0.8591 - val_loss: 0.4163 - val_accuracy: 0.8551\n",
            "Epoch 16/20\n",
            "240/240 [==============================] - 15s 63ms/step - loss: 0.3962 - accuracy: 0.8621 - val_loss: 0.4094 - val_accuracy: 0.8582\n",
            "Epoch 17/20\n",
            "240/240 [==============================] - 15s 63ms/step - loss: 0.3937 - accuracy: 0.8628 - val_loss: 0.4034 - val_accuracy: 0.8582\n",
            "Epoch 18/20\n",
            "240/240 [==============================] - 15s 63ms/step - loss: 0.3850 - accuracy: 0.8673 - val_loss: 0.4069 - val_accuracy: 0.8585\n",
            "Epoch 19/20\n",
            "240/240 [==============================] - 15s 62ms/step - loss: 0.3826 - accuracy: 0.8665 - val_loss: 0.3970 - val_accuracy: 0.8608\n",
            "Epoch 20/20\n",
            "240/240 [==============================] - 15s 60ms/step - loss: 0.3803 - accuracy: 0.8667 - val_loss: 0.3948 - val_accuracy: 0.8632\n",
            "Epoch 1/20\n",
            "240/240 [==============================] - 18s 73ms/step - loss: 1.3013 - accuracy: 0.6406 - val_loss: 0.7931 - val_accuracy: 0.7473\n",
            "Epoch 2/20\n",
            "240/240 [==============================] - 17s 72ms/step - loss: 0.7024 - accuracy: 0.7681 - val_loss: 0.6182 - val_accuracy: 0.7972\n",
            "Epoch 3/20\n",
            "240/240 [==============================] - 17s 70ms/step - loss: 0.5941 - accuracy: 0.7966 - val_loss: 0.5682 - val_accuracy: 0.7947\n",
            "Epoch 4/20\n",
            "240/240 [==============================] - 17s 71ms/step - loss: 0.5433 - accuracy: 0.8122 - val_loss: 0.5269 - val_accuracy: 0.8117\n",
            "Epoch 5/20\n",
            "240/240 [==============================] - 17s 71ms/step - loss: 0.5068 - accuracy: 0.8232 - val_loss: 0.4943 - val_accuracy: 0.8272\n",
            "Epoch 6/20\n",
            "240/240 [==============================] - 17s 72ms/step - loss: 0.4857 - accuracy: 0.8292 - val_loss: 0.5346 - val_accuracy: 0.8127\n",
            "Epoch 7/20\n",
            "240/240 [==============================] - 17s 71ms/step - loss: 0.4701 - accuracy: 0.8357 - val_loss: 0.4803 - val_accuracy: 0.8254\n",
            "Epoch 8/20\n",
            "240/240 [==============================] - 17s 70ms/step - loss: 0.4545 - accuracy: 0.8422 - val_loss: 0.4491 - val_accuracy: 0.8407\n",
            "Epoch 9/20\n",
            "240/240 [==============================] - 17s 72ms/step - loss: 0.4399 - accuracy: 0.8465 - val_loss: 0.4742 - val_accuracy: 0.8325\n",
            "Epoch 10/20\n",
            "240/240 [==============================] - 17s 72ms/step - loss: 0.4290 - accuracy: 0.8494 - val_loss: 0.4252 - val_accuracy: 0.8487\n",
            "Epoch 11/20\n",
            "240/240 [==============================] - 17s 73ms/step - loss: 0.4200 - accuracy: 0.8542 - val_loss: 0.4253 - val_accuracy: 0.8478\n",
            "Epoch 12/20\n",
            "240/240 [==============================] - 17s 71ms/step - loss: 0.4100 - accuracy: 0.8557 - val_loss: 0.4348 - val_accuracy: 0.8437\n",
            "Epoch 13/20\n",
            "240/240 [==============================] - 17s 71ms/step - loss: 0.4063 - accuracy: 0.8586 - val_loss: 0.4164 - val_accuracy: 0.8533\n",
            "Epoch 14/20\n",
            "240/240 [==============================] - 17s 71ms/step - loss: 0.3964 - accuracy: 0.8615 - val_loss: 0.4004 - val_accuracy: 0.8577\n",
            "Epoch 15/20\n",
            "240/240 [==============================] - 17s 72ms/step - loss: 0.3906 - accuracy: 0.8639 - val_loss: 0.4094 - val_accuracy: 0.8565\n",
            "Epoch 16/20\n",
            "240/240 [==============================] - 17s 72ms/step - loss: 0.3837 - accuracy: 0.8654 - val_loss: 0.3958 - val_accuracy: 0.8599\n",
            "Epoch 17/20\n",
            "240/240 [==============================] - 17s 71ms/step - loss: 0.3787 - accuracy: 0.8676 - val_loss: 0.4090 - val_accuracy: 0.8523\n",
            "Epoch 18/20\n",
            "240/240 [==============================] - 17s 70ms/step - loss: 0.3713 - accuracy: 0.8686 - val_loss: 0.4051 - val_accuracy: 0.8561\n",
            "Epoch 19/20\n",
            "240/240 [==============================] - 17s 71ms/step - loss: 0.3688 - accuracy: 0.8705 - val_loss: 0.3941 - val_accuracy: 0.8608\n",
            "Epoch 20/20\n",
            "240/240 [==============================] - 17s 73ms/step - loss: 0.3628 - accuracy: 0.8726 - val_loss: 0.3778 - val_accuracy: 0.8674\n",
            "Epoch 1/20\n",
            "240/240 [==============================] - 18s 75ms/step - loss: 1.3679 - accuracy: 0.6272 - val_loss: 0.7849 - val_accuracy: 0.7548\n",
            "Epoch 2/20\n",
            "240/240 [==============================] - 18s 75ms/step - loss: 0.6908 - accuracy: 0.7654 - val_loss: 0.6251 - val_accuracy: 0.7847\n",
            "Epoch 3/20\n",
            "240/240 [==============================] - 18s 76ms/step - loss: 0.5839 - accuracy: 0.7982 - val_loss: 0.5315 - val_accuracy: 0.8158\n",
            "Epoch 4/20\n",
            "240/240 [==============================] - 18s 74ms/step - loss: 0.5327 - accuracy: 0.8140 - val_loss: 0.5300 - val_accuracy: 0.8069\n",
            "Epoch 5/20\n",
            "240/240 [==============================] - 18s 74ms/step - loss: 0.4987 - accuracy: 0.8254 - val_loss: 0.4820 - val_accuracy: 0.8284\n",
            "Epoch 6/20\n",
            "240/240 [==============================] - 18s 75ms/step - loss: 0.4747 - accuracy: 0.8339 - val_loss: 0.4602 - val_accuracy: 0.8353\n",
            "Epoch 7/20\n",
            "240/240 [==============================] - 18s 74ms/step - loss: 0.4576 - accuracy: 0.8394 - val_loss: 0.4663 - val_accuracy: 0.8388\n",
            "Epoch 8/20\n",
            "240/240 [==============================] - 18s 75ms/step - loss: 0.4418 - accuracy: 0.8468 - val_loss: 0.4388 - val_accuracy: 0.8487\n",
            "Epoch 9/20\n",
            "240/240 [==============================] - 18s 75ms/step - loss: 0.4286 - accuracy: 0.8506 - val_loss: 0.4367 - val_accuracy: 0.8465\n",
            "Epoch 10/20\n",
            "240/240 [==============================] - 18s 75ms/step - loss: 0.4199 - accuracy: 0.8534 - val_loss: 0.4353 - val_accuracy: 0.8468\n",
            "Epoch 11/20\n",
            "240/240 [==============================] - 18s 75ms/step - loss: 0.4097 - accuracy: 0.8566 - val_loss: 0.4728 - val_accuracy: 0.8242\n",
            "Epoch 12/20\n",
            "240/240 [==============================] - 18s 75ms/step - loss: 0.3985 - accuracy: 0.8603 - val_loss: 0.4629 - val_accuracy: 0.8302\n",
            "Epoch 13/20\n",
            "240/240 [==============================] - 18s 75ms/step - loss: 0.3915 - accuracy: 0.8621 - val_loss: 0.4024 - val_accuracy: 0.8574\n",
            "Epoch 14/20\n",
            "240/240 [==============================] - 18s 75ms/step - loss: 0.3836 - accuracy: 0.8654 - val_loss: 0.3943 - val_accuracy: 0.8625\n",
            "Epoch 15/20\n",
            "240/240 [==============================] - 18s 75ms/step - loss: 0.3769 - accuracy: 0.8675 - val_loss: 0.3922 - val_accuracy: 0.8619\n",
            "Epoch 16/20\n",
            "240/240 [==============================] - 18s 75ms/step - loss: 0.3681 - accuracy: 0.8704 - val_loss: 0.3899 - val_accuracy: 0.8656\n",
            "Epoch 17/20\n",
            "240/240 [==============================] - 18s 76ms/step - loss: 0.3643 - accuracy: 0.8716 - val_loss: 0.3791 - val_accuracy: 0.8662\n",
            "Epoch 18/20\n",
            "240/240 [==============================] - 18s 76ms/step - loss: 0.3569 - accuracy: 0.8730 - val_loss: 0.3740 - val_accuracy: 0.8694\n",
            "Epoch 19/20\n",
            "240/240 [==============================] - 18s 75ms/step - loss: 0.3519 - accuracy: 0.8753 - val_loss: 0.3706 - val_accuracy: 0.8687\n",
            "Epoch 20/20\n",
            "240/240 [==============================] - 18s 77ms/step - loss: 0.3509 - accuracy: 0.8755 - val_loss: 0.3713 - val_accuracy: 0.8705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clKW6X422Mq6",
        "outputId": "1b4d86f4-6b8f-45d9-e9d2-5fe98c56e5e1"
      },
      "source": [
        "for i in range(len(sets)):\n",
        "  print(str(sets[i]) + ' hidden layers')\n",
        "  print('accuracy: ', results[i][0])\n",
        "  print('val_accuracy: ' + str(results[i][1]) + '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 700) hidden layers\n",
            "accuracy:  0.8666874766349792\n",
            "val_accuracy: 0.8631666898727417\n",
            "\n",
            "(1000, 700, 500) hidden layers\n",
            "accuracy:  0.8726249933242798\n",
            "val_accuracy: 0.8674166798591614\n",
            "\n",
            "(1000, 700, 500, 200) hidden layers\n",
            "accuracy:  0.8755208253860474\n",
            "val_accuracy: 0.8705000281333923\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HligofXBBSr2"
      },
      "source": [
        "Бачимо, що чим більше прихованих шарів, тим вища якість навчання. Це пояснюється більшою складністю залежності між вхідними і вихідними даними (ширшим простором гіпотез). Це може також призвести до перенавчання, тому необхідно обирати \"золоту середину\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVpE84JP8_54"
      },
      "source": [
        "**4. Використовуйте різну кількість епох: 10, 15, 20, 25, 30. Аргументуйте відповідь.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl1XNwym9GWC",
        "outputId": "e82a126d-0670-4d34-eada-a7174c1e0b1a"
      },
      "source": [
        "epochs = [10, 15, 20, 25, 30]\n",
        "results = []\n",
        "\n",
        "for cur_epochs in epochs:\n",
        "  model = Sequential()\n",
        "  model.add(Dense(800, input_dim=784, activation=\"relu\"))\n",
        "  model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", \n",
        "                metrics=[\"accuracy\"])\n",
        "  history = model.fit(x_train, y_train, batch_size=200, epochs=cur_epochs, \n",
        "                      validation_split=0.2, verbose=1)\n",
        "  results.append((history.history['accuracy'][-1],\n",
        "                  history.history['val_accuracy'][-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 1.2041 - accuracy: 0.6513 - val_loss: 0.8416 - val_accuracy: 0.7478\n",
            "Epoch 2/10\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.7626 - accuracy: 0.7649 - val_loss: 0.6979 - val_accuracy: 0.7804\n",
            "Epoch 3/10\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.6649 - accuracy: 0.7921 - val_loss: 0.6326 - val_accuracy: 0.7959\n",
            "Epoch 4/10\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.6123 - accuracy: 0.8075 - val_loss: 0.5931 - val_accuracy: 0.8073\n",
            "Epoch 5/10\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5778 - accuracy: 0.8153 - val_loss: 0.5666 - val_accuracy: 0.8152\n",
            "Epoch 6/10\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5530 - accuracy: 0.8222 - val_loss: 0.5444 - val_accuracy: 0.8188\n",
            "Epoch 7/10\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5342 - accuracy: 0.8259 - val_loss: 0.5325 - val_accuracy: 0.8198\n",
            "Epoch 8/10\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5190 - accuracy: 0.8300 - val_loss: 0.5162 - val_accuracy: 0.8257\n",
            "Epoch 9/10\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5064 - accuracy: 0.8330 - val_loss: 0.5067 - val_accuracy: 0.8282\n",
            "Epoch 10/10\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4959 - accuracy: 0.8355 - val_loss: 0.4980 - val_accuracy: 0.8307\n",
            "Epoch 1/15\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 1.1951 - accuracy: 0.6556 - val_loss: 0.8407 - val_accuracy: 0.7463\n",
            "Epoch 2/15\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.7665 - accuracy: 0.7636 - val_loss: 0.6983 - val_accuracy: 0.7793\n",
            "Epoch 3/15\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.6676 - accuracy: 0.7919 - val_loss: 0.6311 - val_accuracy: 0.7982\n",
            "Epoch 4/15\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.6141 - accuracy: 0.8061 - val_loss: 0.5925 - val_accuracy: 0.8074\n",
            "Epoch 5/15\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5792 - accuracy: 0.8155 - val_loss: 0.5685 - val_accuracy: 0.8129\n",
            "Epoch 6/15\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5543 - accuracy: 0.8213 - val_loss: 0.5444 - val_accuracy: 0.8205\n",
            "Epoch 7/15\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5349 - accuracy: 0.8265 - val_loss: 0.5273 - val_accuracy: 0.8255\n",
            "Epoch 8/15\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5198 - accuracy: 0.8306 - val_loss: 0.5163 - val_accuracy: 0.8281\n",
            "Epoch 9/15\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5070 - accuracy: 0.8339 - val_loss: 0.5042 - val_accuracy: 0.8319\n",
            "Epoch 10/15\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4960 - accuracy: 0.8355 - val_loss: 0.4958 - val_accuracy: 0.8319\n",
            "Epoch 11/15\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4871 - accuracy: 0.8385 - val_loss: 0.4878 - val_accuracy: 0.8336\n",
            "Epoch 12/15\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4787 - accuracy: 0.8411 - val_loss: 0.4853 - val_accuracy: 0.8332\n",
            "Epoch 13/15\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4716 - accuracy: 0.8422 - val_loss: 0.4744 - val_accuracy: 0.8384\n",
            "Epoch 14/15\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4652 - accuracy: 0.8443 - val_loss: 0.4686 - val_accuracy: 0.8378\n",
            "Epoch 15/15\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4592 - accuracy: 0.8455 - val_loss: 0.4628 - val_accuracy: 0.8407\n",
            "Epoch 1/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 1.1938 - accuracy: 0.6587 - val_loss: 0.8439 - val_accuracy: 0.7453\n",
            "Epoch 2/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.7687 - accuracy: 0.7640 - val_loss: 0.6985 - val_accuracy: 0.7829\n",
            "Epoch 3/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.6697 - accuracy: 0.7921 - val_loss: 0.6327 - val_accuracy: 0.7984\n",
            "Epoch 4/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.6161 - accuracy: 0.8071 - val_loss: 0.5940 - val_accuracy: 0.8087\n",
            "Epoch 5/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5803 - accuracy: 0.8159 - val_loss: 0.5641 - val_accuracy: 0.8201\n",
            "Epoch 6/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5550 - accuracy: 0.8216 - val_loss: 0.5461 - val_accuracy: 0.8199\n",
            "Epoch 7/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5353 - accuracy: 0.8269 - val_loss: 0.5282 - val_accuracy: 0.8255\n",
            "Epoch 8/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5195 - accuracy: 0.8301 - val_loss: 0.5145 - val_accuracy: 0.8295\n",
            "Epoch 9/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5072 - accuracy: 0.8324 - val_loss: 0.5045 - val_accuracy: 0.8316\n",
            "Epoch 10/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4962 - accuracy: 0.8363 - val_loss: 0.4946 - val_accuracy: 0.8333\n",
            "Epoch 11/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4869 - accuracy: 0.8374 - val_loss: 0.4874 - val_accuracy: 0.8347\n",
            "Epoch 12/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4787 - accuracy: 0.8399 - val_loss: 0.4791 - val_accuracy: 0.8366\n",
            "Epoch 13/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4715 - accuracy: 0.8414 - val_loss: 0.4729 - val_accuracy: 0.8383\n",
            "Epoch 14/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4651 - accuracy: 0.8438 - val_loss: 0.4690 - val_accuracy: 0.8388\n",
            "Epoch 15/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4593 - accuracy: 0.8453 - val_loss: 0.4635 - val_accuracy: 0.8402\n",
            "Epoch 16/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4539 - accuracy: 0.8471 - val_loss: 0.4593 - val_accuracy: 0.8435\n",
            "Epoch 17/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4493 - accuracy: 0.8482 - val_loss: 0.4578 - val_accuracy: 0.8422\n",
            "Epoch 18/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4444 - accuracy: 0.8506 - val_loss: 0.4550 - val_accuracy: 0.8437\n",
            "Epoch 19/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4410 - accuracy: 0.8510 - val_loss: 0.4481 - val_accuracy: 0.8438\n",
            "Epoch 20/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4365 - accuracy: 0.8525 - val_loss: 0.4462 - val_accuracy: 0.8452\n",
            "Epoch 1/25\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 1.1756 - accuracy: 0.6590 - val_loss: 0.8366 - val_accuracy: 0.7366\n",
            "Epoch 2/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.7618 - accuracy: 0.7577 - val_loss: 0.6940 - val_accuracy: 0.7747\n",
            "Epoch 3/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.6653 - accuracy: 0.7905 - val_loss: 0.6295 - val_accuracy: 0.7972\n",
            "Epoch 4/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.6126 - accuracy: 0.8057 - val_loss: 0.5902 - val_accuracy: 0.8104\n",
            "Epoch 5/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5778 - accuracy: 0.8148 - val_loss: 0.5643 - val_accuracy: 0.8157\n",
            "Epoch 6/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5526 - accuracy: 0.8215 - val_loss: 0.5459 - val_accuracy: 0.8164\n",
            "Epoch 7/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5336 - accuracy: 0.8264 - val_loss: 0.5268 - val_accuracy: 0.8226\n",
            "Epoch 8/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5185 - accuracy: 0.8294 - val_loss: 0.5137 - val_accuracy: 0.8263\n",
            "Epoch 9/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5058 - accuracy: 0.8328 - val_loss: 0.5043 - val_accuracy: 0.8288\n",
            "Epoch 10/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4956 - accuracy: 0.8357 - val_loss: 0.4931 - val_accuracy: 0.8320\n",
            "Epoch 11/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4859 - accuracy: 0.8382 - val_loss: 0.4889 - val_accuracy: 0.8314\n",
            "Epoch 12/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4782 - accuracy: 0.8410 - val_loss: 0.4786 - val_accuracy: 0.8359\n",
            "Epoch 13/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4711 - accuracy: 0.8422 - val_loss: 0.4777 - val_accuracy: 0.8355\n",
            "Epoch 14/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4646 - accuracy: 0.8437 - val_loss: 0.4698 - val_accuracy: 0.8388\n",
            "Epoch 15/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4592 - accuracy: 0.8450 - val_loss: 0.4651 - val_accuracy: 0.8387\n",
            "Epoch 16/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4539 - accuracy: 0.8466 - val_loss: 0.4602 - val_accuracy: 0.8418\n",
            "Epoch 17/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4492 - accuracy: 0.8483 - val_loss: 0.4540 - val_accuracy: 0.8431\n",
            "Epoch 18/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4448 - accuracy: 0.8490 - val_loss: 0.4510 - val_accuracy: 0.8443\n",
            "Epoch 19/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4406 - accuracy: 0.8503 - val_loss: 0.4477 - val_accuracy: 0.8451\n",
            "Epoch 20/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4365 - accuracy: 0.8521 - val_loss: 0.4440 - val_accuracy: 0.8453\n",
            "Epoch 21/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4325 - accuracy: 0.8539 - val_loss: 0.4441 - val_accuracy: 0.8474\n",
            "Epoch 22/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4292 - accuracy: 0.8540 - val_loss: 0.4376 - val_accuracy: 0.8472\n",
            "Epoch 23/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4265 - accuracy: 0.8543 - val_loss: 0.4350 - val_accuracy: 0.8486\n",
            "Epoch 24/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4237 - accuracy: 0.8555 - val_loss: 0.4327 - val_accuracy: 0.8492\n",
            "Epoch 25/25\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4198 - accuracy: 0.8565 - val_loss: 0.4309 - val_accuracy: 0.8507\n",
            "Epoch 1/30\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 1.2191 - accuracy: 0.6547 - val_loss: 0.8490 - val_accuracy: 0.7382\n",
            "Epoch 2/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.7699 - accuracy: 0.7602 - val_loss: 0.7027 - val_accuracy: 0.7778\n",
            "Epoch 3/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.6694 - accuracy: 0.7883 - val_loss: 0.6361 - val_accuracy: 0.7958\n",
            "Epoch 4/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.6158 - accuracy: 0.8038 - val_loss: 0.5948 - val_accuracy: 0.8071\n",
            "Epoch 5/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5808 - accuracy: 0.8136 - val_loss: 0.5669 - val_accuracy: 0.8142\n",
            "Epoch 6/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5551 - accuracy: 0.8190 - val_loss: 0.5468 - val_accuracy: 0.8191\n",
            "Epoch 7/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5357 - accuracy: 0.8250 - val_loss: 0.5304 - val_accuracy: 0.8227\n",
            "Epoch 8/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5202 - accuracy: 0.8291 - val_loss: 0.5180 - val_accuracy: 0.8262\n",
            "Epoch 9/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5072 - accuracy: 0.8326 - val_loss: 0.5066 - val_accuracy: 0.8306\n",
            "Epoch 10/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4962 - accuracy: 0.8349 - val_loss: 0.4971 - val_accuracy: 0.8300\n",
            "Epoch 11/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4871 - accuracy: 0.8383 - val_loss: 0.4905 - val_accuracy: 0.8328\n",
            "Epoch 12/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4790 - accuracy: 0.8389 - val_loss: 0.4849 - val_accuracy: 0.8332\n",
            "Epoch 13/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4717 - accuracy: 0.8421 - val_loss: 0.4768 - val_accuracy: 0.8363\n",
            "Epoch 14/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4654 - accuracy: 0.8434 - val_loss: 0.4696 - val_accuracy: 0.8397\n",
            "Epoch 15/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4595 - accuracy: 0.8450 - val_loss: 0.4691 - val_accuracy: 0.8386\n",
            "Epoch 16/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4543 - accuracy: 0.8465 - val_loss: 0.4638 - val_accuracy: 0.8409\n",
            "Epoch 17/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4494 - accuracy: 0.8487 - val_loss: 0.4561 - val_accuracy: 0.8432\n",
            "Epoch 18/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4448 - accuracy: 0.8496 - val_loss: 0.4516 - val_accuracy: 0.8457\n",
            "Epoch 19/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4402 - accuracy: 0.8514 - val_loss: 0.4492 - val_accuracy: 0.8450\n",
            "Epoch 20/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4366 - accuracy: 0.8531 - val_loss: 0.4476 - val_accuracy: 0.8447\n",
            "Epoch 21/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4333 - accuracy: 0.8534 - val_loss: 0.4430 - val_accuracy: 0.8487\n",
            "Epoch 22/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4293 - accuracy: 0.8548 - val_loss: 0.4389 - val_accuracy: 0.8474\n",
            "Epoch 23/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4265 - accuracy: 0.8550 - val_loss: 0.4357 - val_accuracy: 0.8497\n",
            "Epoch 24/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4235 - accuracy: 0.8566 - val_loss: 0.4340 - val_accuracy: 0.8500\n",
            "Epoch 25/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4201 - accuracy: 0.8578 - val_loss: 0.4348 - val_accuracy: 0.8491\n",
            "Epoch 26/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4175 - accuracy: 0.8586 - val_loss: 0.4300 - val_accuracy: 0.8507\n",
            "Epoch 27/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4144 - accuracy: 0.8596 - val_loss: 0.4267 - val_accuracy: 0.8515\n",
            "Epoch 28/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4122 - accuracy: 0.8596 - val_loss: 0.4277 - val_accuracy: 0.8512\n",
            "Epoch 29/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4099 - accuracy: 0.8612 - val_loss: 0.4222 - val_accuracy: 0.8530\n",
            "Epoch 30/30\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4071 - accuracy: 0.8612 - val_loss: 0.4216 - val_accuracy: 0.8522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYr__NkD9b6o",
        "outputId": "c9da404f-c103-458b-b9ab-bc29a12de1f1"
      },
      "source": [
        "for i in range(len(epochs)):\n",
        "  print(str(epochs[i]) + ' epochs')\n",
        "  print('accuracy: ', results[i][0])\n",
        "  print('val_accuracy: ' + str(results[i][1]) + '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 epochs\n",
            "accuracy:  0.8354583382606506\n",
            "val_accuracy: 0.8306666612625122\n",
            "\n",
            "15 epochs\n",
            "accuracy:  0.8454791903495789\n",
            "val_accuracy: 0.840666651725769\n",
            "\n",
            "20 epochs\n",
            "accuracy:  0.8525000214576721\n",
            "val_accuracy: 0.8451666831970215\n",
            "\n",
            "25 epochs\n",
            "accuracy:  0.856458306312561\n",
            "val_accuracy: 0.8506666421890259\n",
            "\n",
            "30 epochs\n",
            "accuracy:  0.8612083196640015\n",
            "val_accuracy: 0.8521666526794434\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUnbuonuB79_"
      },
      "source": [
        "Бачимо, що чим більше епох, тим вища якість навчання. З кожною новою епохою нейромережа краще підлаштовується під тренувальний набір (оскільки ми для оптимізації цільової функції використовуємо не весь набір, а batch, то навчання продовжується). Тому занадто велика кількість епох може призвести до перенавчання."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Upoyyi9HAZlc"
      },
      "source": [
        "**5. Використовуйте різні розміри міні-вибірки (batch_size): 10, 50, 100, 200, 500. Аргументуйте відповідь.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCbn2P1yAhOO",
        "outputId": "1e5a2388-0081-4949-ef4a-a2658daecc18"
      },
      "source": [
        "batches = [10, 50, 100, 200, 500]\n",
        "results = []\n",
        "\n",
        "for batch in batches:\n",
        "  model = Sequential()\n",
        "  model.add(Dense(800, input_dim=784, activation=\"relu\"))\n",
        "  model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", \n",
        "                metrics=[\"accuracy\"])\n",
        "  history = model.fit(x_train, y_train, batch_size=batch, epochs=20, \n",
        "                      validation_split=0.2, verbose=1)\n",
        "  results.append((history.history['accuracy'][-1],\n",
        "                  history.history['val_accuracy'][-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4800/4800 [==============================] - 18s 4ms/step - loss: 0.5907 - accuracy: 0.8010 - val_loss: 0.4739 - val_accuracy: 0.8311\n",
            "Epoch 2/20\n",
            "4800/4800 [==============================] - 17s 3ms/step - loss: 0.4401 - accuracy: 0.8479 - val_loss: 0.4282 - val_accuracy: 0.8465\n",
            "Epoch 3/20\n",
            "4800/4800 [==============================] - 17s 4ms/step - loss: 0.3974 - accuracy: 0.8612 - val_loss: 0.4051 - val_accuracy: 0.8537\n",
            "Epoch 4/20\n",
            "4800/4800 [==============================] - 18s 4ms/step - loss: 0.3730 - accuracy: 0.8681 - val_loss: 0.3933 - val_accuracy: 0.8609\n",
            "Epoch 5/20\n",
            "4800/4800 [==============================] - 18s 4ms/step - loss: 0.3534 - accuracy: 0.8762 - val_loss: 0.3603 - val_accuracy: 0.8734\n",
            "Epoch 6/20\n",
            "4800/4800 [==============================] - 18s 4ms/step - loss: 0.3379 - accuracy: 0.8795 - val_loss: 0.3515 - val_accuracy: 0.8752\n",
            "Epoch 7/20\n",
            "4800/4800 [==============================] - 17s 4ms/step - loss: 0.3247 - accuracy: 0.8842 - val_loss: 0.3580 - val_accuracy: 0.8699\n",
            "Epoch 8/20\n",
            "4800/4800 [==============================] - 17s 4ms/step - loss: 0.3125 - accuracy: 0.8887 - val_loss: 0.3690 - val_accuracy: 0.8644\n",
            "Epoch 9/20\n",
            "4800/4800 [==============================] - 17s 3ms/step - loss: 0.3030 - accuracy: 0.8926 - val_loss: 0.3312 - val_accuracy: 0.8813\n",
            "Epoch 10/20\n",
            "4800/4800 [==============================] - 17s 3ms/step - loss: 0.2928 - accuracy: 0.8963 - val_loss: 0.3578 - val_accuracy: 0.8754\n",
            "Epoch 11/20\n",
            "4800/4800 [==============================] - 17s 4ms/step - loss: 0.2841 - accuracy: 0.8985 - val_loss: 0.3225 - val_accuracy: 0.8833\n",
            "Epoch 12/20\n",
            "4800/4800 [==============================] - 17s 4ms/step - loss: 0.2759 - accuracy: 0.9028 - val_loss: 0.3378 - val_accuracy: 0.8792\n",
            "Epoch 13/20\n",
            "4800/4800 [==============================] - 18s 4ms/step - loss: 0.2680 - accuracy: 0.9041 - val_loss: 0.3182 - val_accuracy: 0.8835\n",
            "Epoch 14/20\n",
            "4800/4800 [==============================] - 18s 4ms/step - loss: 0.2622 - accuracy: 0.9066 - val_loss: 0.3128 - val_accuracy: 0.8890\n",
            "Epoch 15/20\n",
            "4800/4800 [==============================] - 20s 4ms/step - loss: 0.2554 - accuracy: 0.9085 - val_loss: 0.3104 - val_accuracy: 0.8888\n",
            "Epoch 16/20\n",
            "4800/4800 [==============================] - 20s 4ms/step - loss: 0.2488 - accuracy: 0.9107 - val_loss: 0.3181 - val_accuracy: 0.8851\n",
            "Epoch 17/20\n",
            "4800/4800 [==============================] - 19s 4ms/step - loss: 0.2420 - accuracy: 0.9136 - val_loss: 0.3086 - val_accuracy: 0.8891\n",
            "Epoch 18/20\n",
            "4800/4800 [==============================] - 19s 4ms/step - loss: 0.2372 - accuracy: 0.9162 - val_loss: 0.3081 - val_accuracy: 0.8887\n",
            "Epoch 19/20\n",
            "4800/4800 [==============================] - 18s 4ms/step - loss: 0.2314 - accuracy: 0.9187 - val_loss: 0.3115 - val_accuracy: 0.8854\n",
            "Epoch 20/20\n",
            "4800/4800 [==============================] - 19s 4ms/step - loss: 0.2265 - accuracy: 0.9194 - val_loss: 0.3056 - val_accuracy: 0.8921\n",
            "Epoch 1/20\n",
            "960/960 [==============================] - 7s 7ms/step - loss: 0.8216 - accuracy: 0.7478 - val_loss: 0.6144 - val_accuracy: 0.7918\n",
            "Epoch 2/20\n",
            "960/960 [==============================] - 7s 7ms/step - loss: 0.5527 - accuracy: 0.8184 - val_loss: 0.5194 - val_accuracy: 0.8253\n",
            "Epoch 3/20\n",
            "960/960 [==============================] - 7s 7ms/step - loss: 0.4999 - accuracy: 0.8320 - val_loss: 0.4850 - val_accuracy: 0.8342\n",
            "Epoch 4/20\n",
            "960/960 [==============================] - 7s 7ms/step - loss: 0.4698 - accuracy: 0.8420 - val_loss: 0.4786 - val_accuracy: 0.8333\n",
            "Epoch 5/20\n",
            "960/960 [==============================] - 7s 7ms/step - loss: 0.4494 - accuracy: 0.8480 - val_loss: 0.4493 - val_accuracy: 0.8437\n",
            "Epoch 6/20\n",
            "960/960 [==============================] - 7s 7ms/step - loss: 0.4353 - accuracy: 0.8510 - val_loss: 0.4394 - val_accuracy: 0.8508\n",
            "Epoch 7/20\n",
            "960/960 [==============================] - 7s 7ms/step - loss: 0.4233 - accuracy: 0.8554 - val_loss: 0.4308 - val_accuracy: 0.8497\n",
            "Epoch 8/20\n",
            "960/960 [==============================] - 7s 7ms/step - loss: 0.4130 - accuracy: 0.8586 - val_loss: 0.4232 - val_accuracy: 0.8543\n",
            "Epoch 9/20\n",
            "960/960 [==============================] - 7s 7ms/step - loss: 0.4034 - accuracy: 0.8626 - val_loss: 0.4178 - val_accuracy: 0.8561\n",
            "Epoch 10/20\n",
            "960/960 [==============================] - 7s 7ms/step - loss: 0.3951 - accuracy: 0.8636 - val_loss: 0.4044 - val_accuracy: 0.8616\n",
            "Epoch 11/20\n",
            "960/960 [==============================] - 7s 7ms/step - loss: 0.3883 - accuracy: 0.8672 - val_loss: 0.3984 - val_accuracy: 0.8622\n",
            "Epoch 12/20\n",
            "960/960 [==============================] - 7s 7ms/step - loss: 0.3819 - accuracy: 0.8671 - val_loss: 0.3954 - val_accuracy: 0.8627\n",
            "Epoch 13/20\n",
            "960/960 [==============================] - 7s 7ms/step - loss: 0.3757 - accuracy: 0.8699 - val_loss: 0.4047 - val_accuracy: 0.8590\n",
            "Epoch 14/20\n",
            "960/960 [==============================] - 7s 7ms/step - loss: 0.3699 - accuracy: 0.8727 - val_loss: 0.3973 - val_accuracy: 0.8618\n",
            "Epoch 15/20\n",
            "960/960 [==============================] - 7s 7ms/step - loss: 0.3644 - accuracy: 0.8736 - val_loss: 0.3866 - val_accuracy: 0.8654\n",
            "Epoch 16/20\n",
            "960/960 [==============================] - 7s 7ms/step - loss: 0.3595 - accuracy: 0.8757 - val_loss: 0.3872 - val_accuracy: 0.8649\n",
            "Epoch 17/20\n",
            "960/960 [==============================] - 7s 7ms/step - loss: 0.3549 - accuracy: 0.8762 - val_loss: 0.3750 - val_accuracy: 0.8677\n",
            "Epoch 18/20\n",
            "960/960 [==============================] - 7s 7ms/step - loss: 0.3509 - accuracy: 0.8775 - val_loss: 0.3767 - val_accuracy: 0.8684\n",
            "Epoch 19/20\n",
            "960/960 [==============================] - 7s 7ms/step - loss: 0.3463 - accuracy: 0.8802 - val_loss: 0.3686 - val_accuracy: 0.8724\n",
            "Epoch 20/20\n",
            "960/960 [==============================] - 7s 7ms/step - loss: 0.3426 - accuracy: 0.8797 - val_loss: 0.3809 - val_accuracy: 0.8648\n",
            "Epoch 1/20\n",
            "480/480 [==============================] - 6s 11ms/step - loss: 0.9908 - accuracy: 0.7019 - val_loss: 0.7041 - val_accuracy: 0.7747\n",
            "Epoch 2/20\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.6485 - accuracy: 0.7962 - val_loss: 0.5954 - val_accuracy: 0.8048\n",
            "Epoch 3/20\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.5726 - accuracy: 0.8148 - val_loss: 0.5554 - val_accuracy: 0.8127\n",
            "Epoch 4/20\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.5324 - accuracy: 0.8261 - val_loss: 0.5238 - val_accuracy: 0.8226\n",
            "Epoch 5/20\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.5060 - accuracy: 0.8330 - val_loss: 0.5010 - val_accuracy: 0.8298\n",
            "Epoch 6/20\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.4875 - accuracy: 0.8368 - val_loss: 0.4818 - val_accuracy: 0.8342\n",
            "Epoch 7/20\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.4727 - accuracy: 0.8414 - val_loss: 0.4694 - val_accuracy: 0.8387\n",
            "Epoch 8/20\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.4603 - accuracy: 0.8455 - val_loss: 0.4614 - val_accuracy: 0.8421\n",
            "Epoch 9/20\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.4505 - accuracy: 0.8475 - val_loss: 0.4549 - val_accuracy: 0.8438\n",
            "Epoch 10/20\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.4425 - accuracy: 0.8508 - val_loss: 0.4505 - val_accuracy: 0.8456\n",
            "Epoch 11/20\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.4349 - accuracy: 0.8518 - val_loss: 0.4412 - val_accuracy: 0.8479\n",
            "Epoch 12/20\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.4283 - accuracy: 0.8543 - val_loss: 0.4357 - val_accuracy: 0.8496\n",
            "Epoch 13/20\n",
            "480/480 [==============================] - 5s 11ms/step - loss: 0.4225 - accuracy: 0.8568 - val_loss: 0.4312 - val_accuracy: 0.8528\n",
            "Epoch 14/20\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.4170 - accuracy: 0.8573 - val_loss: 0.4317 - val_accuracy: 0.8492\n",
            "Epoch 15/20\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.4116 - accuracy: 0.8596 - val_loss: 0.4249 - val_accuracy: 0.8541\n",
            "Epoch 16/20\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.4075 - accuracy: 0.8614 - val_loss: 0.4179 - val_accuracy: 0.8567\n",
            "Epoch 17/20\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.4027 - accuracy: 0.8629 - val_loss: 0.4160 - val_accuracy: 0.8573\n",
            "Epoch 18/20\n",
            "480/480 [==============================] - 5s 11ms/step - loss: 0.3982 - accuracy: 0.8637 - val_loss: 0.4124 - val_accuracy: 0.8583\n",
            "Epoch 19/20\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.3940 - accuracy: 0.8661 - val_loss: 0.4111 - val_accuracy: 0.8601\n",
            "Epoch 20/20\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.3910 - accuracy: 0.8677 - val_loss: 0.4030 - val_accuracy: 0.8613\n",
            "Epoch 1/20\n",
            "240/240 [==============================] - 5s 19ms/step - loss: 1.2022 - accuracy: 0.6490 - val_loss: 0.8405 - val_accuracy: 0.7444\n",
            "Epoch 2/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.7644 - accuracy: 0.7658 - val_loss: 0.6941 - val_accuracy: 0.7825\n",
            "Epoch 3/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.6652 - accuracy: 0.7940 - val_loss: 0.6304 - val_accuracy: 0.8002\n",
            "Epoch 4/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.6119 - accuracy: 0.8066 - val_loss: 0.5902 - val_accuracy: 0.8093\n",
            "Epoch 5/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5771 - accuracy: 0.8158 - val_loss: 0.5620 - val_accuracy: 0.8183\n",
            "Epoch 6/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5522 - accuracy: 0.8211 - val_loss: 0.5431 - val_accuracy: 0.8204\n",
            "Epoch 7/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5329 - accuracy: 0.8257 - val_loss: 0.5285 - val_accuracy: 0.8224\n",
            "Epoch 8/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5180 - accuracy: 0.8302 - val_loss: 0.5134 - val_accuracy: 0.8268\n",
            "Epoch 9/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.5055 - accuracy: 0.8333 - val_loss: 0.5037 - val_accuracy: 0.8290\n",
            "Epoch 10/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4947 - accuracy: 0.8359 - val_loss: 0.4946 - val_accuracy: 0.8313\n",
            "Epoch 11/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4860 - accuracy: 0.8380 - val_loss: 0.4866 - val_accuracy: 0.8346\n",
            "Epoch 12/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4782 - accuracy: 0.8399 - val_loss: 0.4824 - val_accuracy: 0.8333\n",
            "Epoch 13/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4713 - accuracy: 0.8425 - val_loss: 0.4751 - val_accuracy: 0.8373\n",
            "Epoch 14/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4646 - accuracy: 0.8439 - val_loss: 0.4712 - val_accuracy: 0.8346\n",
            "Epoch 15/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4590 - accuracy: 0.8454 - val_loss: 0.4647 - val_accuracy: 0.8382\n",
            "Epoch 16/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4541 - accuracy: 0.8474 - val_loss: 0.4589 - val_accuracy: 0.8406\n",
            "Epoch 17/20\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.4489 - accuracy: 0.8482 - val_loss: 0.4579 - val_accuracy: 0.8386\n",
            "Epoch 18/20\n",
            "240/240 [==============================] - 4s 16ms/step - loss: 0.4446 - accuracy: 0.8503 - val_loss: 0.4507 - val_accuracy: 0.8432\n",
            "Epoch 19/20\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.4405 - accuracy: 0.8518 - val_loss: 0.4475 - val_accuracy: 0.8450\n",
            "Epoch 20/20\n",
            "240/240 [==============================] - 4s 17ms/step - loss: 0.4366 - accuracy: 0.8522 - val_loss: 0.4436 - val_accuracy: 0.8459\n",
            "Epoch 1/20\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 1.5455 - accuracy: 0.5852 - val_loss: 1.1222 - val_accuracy: 0.6990\n",
            "Epoch 2/20\n",
            "96/96 [==============================] - 3s 34ms/step - loss: 0.9953 - accuracy: 0.7136 - val_loss: 0.8885 - val_accuracy: 0.7377\n",
            "Epoch 3/20\n",
            "96/96 [==============================] - 3s 33ms/step - loss: 0.8430 - accuracy: 0.7445 - val_loss: 0.7890 - val_accuracy: 0.7600\n",
            "Epoch 4/20\n",
            "96/96 [==============================] - 3s 34ms/step - loss: 0.7661 - accuracy: 0.7640 - val_loss: 0.7314 - val_accuracy: 0.7747\n",
            "Epoch 5/20\n",
            "96/96 [==============================] - 3s 33ms/step - loss: 0.7169 - accuracy: 0.7774 - val_loss: 0.6909 - val_accuracy: 0.7848\n",
            "Epoch 6/20\n",
            "96/96 [==============================] - 3s 33ms/step - loss: 0.6813 - accuracy: 0.7876 - val_loss: 0.6620 - val_accuracy: 0.7908\n",
            "Epoch 7/20\n",
            "96/96 [==============================] - 3s 33ms/step - loss: 0.6541 - accuracy: 0.7947 - val_loss: 0.6378 - val_accuracy: 0.7956\n",
            "Epoch 8/20\n",
            "96/96 [==============================] - 3s 33ms/step - loss: 0.6321 - accuracy: 0.8001 - val_loss: 0.6201 - val_accuracy: 0.7997\n",
            "Epoch 9/20\n",
            "96/96 [==============================] - 3s 34ms/step - loss: 0.6137 - accuracy: 0.8051 - val_loss: 0.6034 - val_accuracy: 0.8054\n",
            "Epoch 10/20\n",
            "96/96 [==============================] - 3s 34ms/step - loss: 0.5981 - accuracy: 0.8090 - val_loss: 0.5916 - val_accuracy: 0.8085\n",
            "Epoch 11/20\n",
            "96/96 [==============================] - 3s 34ms/step - loss: 0.5848 - accuracy: 0.8128 - val_loss: 0.5789 - val_accuracy: 0.8117\n",
            "Epoch 12/20\n",
            "96/96 [==============================] - 3s 33ms/step - loss: 0.5732 - accuracy: 0.8150 - val_loss: 0.5676 - val_accuracy: 0.8142\n",
            "Epoch 13/20\n",
            "96/96 [==============================] - 3s 33ms/step - loss: 0.5627 - accuracy: 0.8182 - val_loss: 0.5589 - val_accuracy: 0.8159\n",
            "Epoch 14/20\n",
            "96/96 [==============================] - 3s 33ms/step - loss: 0.5538 - accuracy: 0.8197 - val_loss: 0.5503 - val_accuracy: 0.8183\n",
            "Epoch 15/20\n",
            "96/96 [==============================] - 3s 33ms/step - loss: 0.5454 - accuracy: 0.8221 - val_loss: 0.5433 - val_accuracy: 0.8183\n",
            "Epoch 16/20\n",
            "96/96 [==============================] - 3s 33ms/step - loss: 0.5380 - accuracy: 0.8240 - val_loss: 0.5382 - val_accuracy: 0.8198\n",
            "Epoch 17/20\n",
            "96/96 [==============================] - 3s 33ms/step - loss: 0.5316 - accuracy: 0.8251 - val_loss: 0.5313 - val_accuracy: 0.8217\n",
            "Epoch 18/20\n",
            "96/96 [==============================] - 3s 34ms/step - loss: 0.5251 - accuracy: 0.8275 - val_loss: 0.5256 - val_accuracy: 0.8238\n",
            "Epoch 19/20\n",
            "96/96 [==============================] - 3s 33ms/step - loss: 0.5192 - accuracy: 0.8279 - val_loss: 0.5202 - val_accuracy: 0.8238\n",
            "Epoch 20/20\n",
            "96/96 [==============================] - 3s 34ms/step - loss: 0.5141 - accuracy: 0.8296 - val_loss: 0.5148 - val_accuracy: 0.8254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOM7iz4WAy4e",
        "outputId": "7aeaa1a5-b8d5-4d9e-8b14-10865fa1771a"
      },
      "source": [
        "for i in range(len(batches)):\n",
        "  print(str(batches[i]) + ' samples in batch')\n",
        "  print('accuracy: ', results[i][0])\n",
        "  print('val_accuracy: ' + str(results[i][1]) + '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 samples in batch\n",
            "accuracy:  0.9194166660308838\n",
            "val_accuracy: 0.8920833468437195\n",
            "\n",
            "50 samples in batch\n",
            "accuracy:  0.8797083497047424\n",
            "val_accuracy: 0.8647500276565552\n",
            "\n",
            "100 samples in batch\n",
            "accuracy:  0.8677499890327454\n",
            "val_accuracy: 0.8613333106040955\n",
            "\n",
            "200 samples in batch\n",
            "accuracy:  0.8521666526794434\n",
            "val_accuracy: 0.8459166884422302\n",
            "\n",
            "500 samples in batch\n",
            "accuracy:  0.8295624852180481\n",
            "val_accuracy: 0.8254166841506958\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeKlchNcC68o"
      },
      "source": [
        "Бачимо, що для даного набору менший розмір міні-вибірки дає кращий результат. Беручи меншу міні-вибірку ми також запобігаємо перенавчанню моделі."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3MHMCIFFEal"
      },
      "source": [
        "**Підберіть різні комбінації гіперпараметрів таким чином, щоб отримати кращий результат на тестовому наборі даних.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9ZBqXUWFIzv"
      },
      "source": [
        "Візьмемо:\n",
        "* 800 нейронів у вхідному шарі\n",
        "* 2 прихованих шари з 400 нейронами\n",
        "* міні-вибірку розміру 10\n",
        "* 14 епох"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neQUaMQnFrYr",
        "outputId": "2c0b721f-d4c2-4ad1-b449-4e50c2ca6946"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(800, input_dim=784, activation=\"relu\"))\n",
        "model.add(Dense(400, activation=\"relu\"))\n",
        "model.add(Dense(400, activation=\"relu\"))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", \n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(x_train, y_train, batch_size=10, epochs=15, \n",
        "                    validation_split=0.2, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "4800/4800 [==============================] - 39s 8ms/step - loss: 0.5749 - accuracy: 0.7988 - val_loss: 0.4233 - val_accuracy: 0.8460\n",
            "Epoch 2/15\n",
            "4800/4800 [==============================] - 35s 7ms/step - loss: 0.4037 - accuracy: 0.8541 - val_loss: 0.3880 - val_accuracy: 0.8614\n",
            "Epoch 3/15\n",
            "4800/4800 [==============================] - 38s 8ms/step - loss: 0.3573 - accuracy: 0.8704 - val_loss: 0.3706 - val_accuracy: 0.8683\n",
            "Epoch 4/15\n",
            "4800/4800 [==============================] - 36s 8ms/step - loss: 0.3308 - accuracy: 0.8789 - val_loss: 0.3982 - val_accuracy: 0.8540\n",
            "Epoch 5/15\n",
            "4800/4800 [==============================] - 38s 8ms/step - loss: 0.3095 - accuracy: 0.8853 - val_loss: 0.3654 - val_accuracy: 0.8652\n",
            "Epoch 6/15\n",
            "4800/4800 [==============================] - 36s 8ms/step - loss: 0.2912 - accuracy: 0.8922 - val_loss: 0.3236 - val_accuracy: 0.8836\n",
            "Epoch 7/15\n",
            "4800/4800 [==============================] - 38s 8ms/step - loss: 0.2751 - accuracy: 0.8988 - val_loss: 0.3516 - val_accuracy: 0.8686\n",
            "Epoch 8/15\n",
            "4800/4800 [==============================] - 39s 8ms/step - loss: 0.2627 - accuracy: 0.9024 - val_loss: 0.3178 - val_accuracy: 0.8852\n",
            "Epoch 9/15\n",
            "4800/4800 [==============================] - 40s 8ms/step - loss: 0.2518 - accuracy: 0.9064 - val_loss: 0.3386 - val_accuracy: 0.8786\n",
            "Epoch 10/15\n",
            "4800/4800 [==============================] - 40s 8ms/step - loss: 0.2398 - accuracy: 0.9103 - val_loss: 0.3200 - val_accuracy: 0.8850\n",
            "Epoch 11/15\n",
            "4800/4800 [==============================] - 39s 8ms/step - loss: 0.2287 - accuracy: 0.9150 - val_loss: 0.3072 - val_accuracy: 0.8928\n",
            "Epoch 12/15\n",
            "4800/4800 [==============================] - 39s 8ms/step - loss: 0.2210 - accuracy: 0.9187 - val_loss: 0.3146 - val_accuracy: 0.8880\n",
            "Epoch 13/15\n",
            "4800/4800 [==============================] - 39s 8ms/step - loss: 0.2114 - accuracy: 0.9211 - val_loss: 0.3144 - val_accuracy: 0.8875\n",
            "Epoch 14/15\n",
            "4800/4800 [==============================] - 40s 8ms/step - loss: 0.2026 - accuracy: 0.9258 - val_loss: 0.3160 - val_accuracy: 0.8888\n",
            "Epoch 15/15\n",
            "4800/4800 [==============================] - 40s 8ms/step - loss: 0.1942 - accuracy: 0.9276 - val_loss: 0.3186 - val_accuracy: 0.8903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzvsMhxXGHYO",
        "outputId": "1b3b28b9-89f5-4ef5-a09d-f3c899adb427"
      },
      "source": [
        "print('accuracy: ', history.history['accuracy'][-1])\n",
        "print('val_accuracy: ', history.history['val_accuracy'][-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.9276041388511658\n",
            "val_accuracy:  0.890333354473114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdjP7EOsarnM"
      },
      "source": [
        "За історією поепохового навчання бачимо, що перенавчання не відбулося. Параметри були підібрані таким чином, щоб досягти результату близького до найкращого. "
      ]
    }
  ]
}